{
  "cells": [
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "M7KYj8EtoPxZ"
      },
      "source": [
        "# Constants:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "ZsusFSopoVfn"
      },
      "outputs": [],
      "source": [
        "SEQ_LEN = 180 #240   # how many past candles to use to predict\n",
        "CANDLES_SHIFT = 2 #5 # how many candles to shift between sequences\n",
        "NAME = \"pp3_m5_ov40th004p_shift2_seq180\"\n",
        "VALIDATION_PCT = 0.2"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "oSqPTNz-m5fo"
      },
      "source": [
        "# Functions:"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "1V8NN17CqWGA"
      },
      "source": [
        "sequence split"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {},
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "\n",
        "def splitDf_new(df):\n",
        "    \n",
        "    res = []\n",
        "    print(\"\")\n",
        "    print(\"splitDf\")\n",
        "    while len(df) >= SEQ_LEN:\n",
        "        first = df.head(SEQ_LEN).copy()\n",
        "        first.index = np.arange(0, len(first))\n",
        "        res.append(first)\n",
        "        df = df.tail(len(df) - CANDLES_SHIFT)\n",
        "        df.index = np.arange(0, len(df))\n",
        "\n",
        "    print(\"-done\")\n",
        "    print(\"\")\n",
        "    return res"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "v84s4MzlrJex"
      },
      "source": [
        "balance"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "Hddt3uD8rLYE"
      },
      "outputs": [],
      "source": [
        "def balance(dfs):\n",
        "    \n",
        "    buys = []\n",
        "    sells = []\n",
        "    holds = []\n",
        "    for df in dfs:\n",
        "        if df.at[len(df)-1, 'target'] == 0:\n",
        "            sells.append(df)\n",
        "        elif df.at[len(df)-1, 'target'] == 1:\n",
        "            buys.append(df)\n",
        "        else:\n",
        "          holds.append(df)\n",
        "\n",
        "    print(\"before balancing:\")\n",
        "    print(\"buys:\", len(buys), \", sells:\", len(sells), \", holds:\", len(holds))\n",
        "\n",
        "    smallest = min(len(buys), len(sells), len(holds))\n",
        "    buys = buys[:smallest]\n",
        "    sells = sells[:smallest]\n",
        "    holds = holds[:smallest]\n",
        "\n",
        "    dfsBalanced = buys+sells+holds\n",
        "    return dfsBalanced"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "puLrLHQCr2IF"
      },
      "source": [
        "preprocessing"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {},
      "outputs": [],
      "source": [
        "from sklearn.preprocessing import StandardScaler\n",
        "\n",
        "\n",
        "# Function to preprocess data\n",
        "def preprocess3_train(df):\n",
        "    # before sequencing\n",
        "    #\n",
        "    # log and pctchange transform price columns ('low', 'high', 'open', 'close')\n",
        "    # scale every colum (center mean and unit variance)\n",
        "\n",
        "    scaler_dict = {}\n",
        "    for col in df.columns:\n",
        "        if col != 'target':\n",
        "            if col != 'quantity_baseUnits' and col != 'hl_percent':\n",
        "                df[col] = np.log(df[col])\n",
        "                df[col] = df[col].pct_change()\n",
        "                df.dropna(inplace=True)\n",
        "            scaler = StandardScaler()\n",
        "            df[col] = scaler.fit_transform(df[col].values.reshape(-1, 1))\n",
        "            scaler_dict[col] = scaler\n",
        "    df.index = np.arange(0, len(df))\n",
        "    return df, scaler_dict\n",
        "\n",
        "# Function to apply saved preprocessing to new data\n",
        "def apply_preprocess3_val(df, scaler_dict):\n",
        "    # before sequencing\n",
        "    #\n",
        "    # pct.change transform price columns ('low', 'high', 'open', 'close')\n",
        "    # scale every colum (center mean and unit variance)\n",
        "    \n",
        "    for col in df.columns:\n",
        "        if col != 'target':\n",
        "            if col != 'quantity_baseUnits' and col != 'hl_percent':\n",
        "                df[col] = np.log(df[col])\n",
        "                df[col] = df[col].pct_change()\n",
        "                df.dropna(inplace=True)\n",
        "            scaler = scaler_dict[col]\n",
        "            df[col] = scaler.transform(df[col].values.reshape(-1, 1))\n",
        "    df.index = np.arange(0, len(df))\n",
        "    return df"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "Mtk_1EDotEdd"
      },
      "source": [
        "sequences"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "U4r2br77tGf-"
      },
      "outputs": [],
      "source": [
        "def buildSequences(dfs):\n",
        "    \n",
        "    sequences = []\n",
        "    for df in dfs:\n",
        "        if(len(df) == SEQ_LEN):\n",
        "            label = df.at[SEQ_LEN-1, 'target']\n",
        "            df = df.iloc[:, :-1]\n",
        "            dfArray = df.values.tolist()\n",
        "            sequences.append([np.array(dfArray), label])\n",
        "    \n",
        "    return sequences"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "Dd640LH1tix2"
      },
      "source": [
        "X y split"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "4-HIbtKAtj-0"
      },
      "outputs": [],
      "source": [
        "def xySplit(seqWithTarget):\n",
        "\n",
        "    X = []\n",
        "    y = []\n",
        "    for seq, target in seqWithTarget:\n",
        "        X.append(seq)\n",
        "        y.append(target)\n",
        "\n",
        "    return np.array(X),np.array(y)"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "bBfc_4lKnYpv"
      },
      "source": [
        "# DF manipulation, build training sets:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>close</th>\n",
              "      <th>low</th>\n",
              "      <th>high</th>\n",
              "      <th>weightedAverage</th>\n",
              "      <th>hl_percent</th>\n",
              "      <th>quantity_baseUnits</th>\n",
              "      <th>target</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>681.84</td>\n",
              "      <td>678.01</td>\n",
              "      <td>681.84</td>\n",
              "      <td>679.87</td>\n",
              "      <td>0.005617</td>\n",
              "      <td>0.488352</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>683.40</td>\n",
              "      <td>678.12</td>\n",
              "      <td>683.53</td>\n",
              "      <td>682.69</td>\n",
              "      <td>0.007915</td>\n",
              "      <td>0.239165</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>681.95</td>\n",
              "      <td>681.95</td>\n",
              "      <td>683.37</td>\n",
              "      <td>683.01</td>\n",
              "      <td>0.002078</td>\n",
              "      <td>0.103008</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>678.86</td>\n",
              "      <td>678.86</td>\n",
              "      <td>684.89</td>\n",
              "      <td>684.00</td>\n",
              "      <td>0.008804</td>\n",
              "      <td>9.084392</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>684.39</td>\n",
              "      <td>684.39</td>\n",
              "      <td>684.73</td>\n",
              "      <td>684.55</td>\n",
              "      <td>0.000497</td>\n",
              "      <td>0.236453</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>736051</th>\n",
              "      <td>30408.88</td>\n",
              "      <td>30405.38</td>\n",
              "      <td>30415.48</td>\n",
              "      <td>30409.02</td>\n",
              "      <td>0.000332</td>\n",
              "      <td>0.091832</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>736052</th>\n",
              "      <td>30413.16</td>\n",
              "      <td>30408.38</td>\n",
              "      <td>30414.80</td>\n",
              "      <td>30409.77</td>\n",
              "      <td>0.000211</td>\n",
              "      <td>0.128622</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>736053</th>\n",
              "      <td>30414.06</td>\n",
              "      <td>30409.65</td>\n",
              "      <td>30420.01</td>\n",
              "      <td>30413.24</td>\n",
              "      <td>0.000341</td>\n",
              "      <td>0.090499</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>736054</th>\n",
              "      <td>30426.45</td>\n",
              "      <td>30411.67</td>\n",
              "      <td>30427.69</td>\n",
              "      <td>30419.85</td>\n",
              "      <td>0.000526</td>\n",
              "      <td>0.205135</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>736055</th>\n",
              "      <td>30439.96</td>\n",
              "      <td>30419.53</td>\n",
              "      <td>30440.99</td>\n",
              "      <td>30427.60</td>\n",
              "      <td>0.000705</td>\n",
              "      <td>0.094435</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>736056 rows Ã— 7 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "           close       low      high  weightedAverage  hl_percent  \\\n",
              "0         681.84    678.01    681.84           679.87    0.005617   \n",
              "1         683.40    678.12    683.53           682.69    0.007915   \n",
              "2         681.95    681.95    683.37           683.01    0.002078   \n",
              "3         678.86    678.86    684.89           684.00    0.008804   \n",
              "4         684.39    684.39    684.73           684.55    0.000497   \n",
              "...          ...       ...       ...              ...         ...   \n",
              "736051  30408.88  30405.38  30415.48         30409.02    0.000332   \n",
              "736052  30413.16  30408.38  30414.80         30409.77    0.000211   \n",
              "736053  30414.06  30409.65  30420.01         30413.24    0.000341   \n",
              "736054  30426.45  30411.67  30427.69         30419.85    0.000526   \n",
              "736055  30439.96  30419.53  30440.99         30427.60    0.000705   \n",
              "\n",
              "        quantity_baseUnits  target  \n",
              "0                 0.488352       0  \n",
              "1                 0.239165       0  \n",
              "2                 0.103008       0  \n",
              "3                 9.084392       0  \n",
              "4                 0.236453       0  \n",
              "...                    ...     ...  \n",
              "736051            0.091832       0  \n",
              "736052            0.128622       0  \n",
              "736053            0.090499       0  \n",
              "736054            0.205135       0  \n",
              "736055            0.094435       0  \n",
              "\n",
              "[736056 rows x 7 columns]"
            ]
          },
          "execution_count": 7,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "import pandas as pd\n",
        "df = pd.read_csv(\"../historicalData/labeled/HistoricalDataLabeled_BTC_USDT_01072016_01072023_MINUTE_5_ov40_th004p.csv\")\n",
        "df = df[['close', 'weightedAverage', 'hl_percent', 'quantity_baseUnits', 'target']]\n",
        "df"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Split data into train and validation sets\n",
        "train_size = int((1-VALIDATION_PCT) * len(df))\n",
        "train_df = df.iloc[:train_size].copy()\n",
        "val_df = df.iloc[train_size:].copy()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Preprocess the training data and save the scaling parameters\n",
        "train_df, scaler_dict = preprocess3_train(train_df)\n",
        "# Apply saved preprocessing to validation data\n",
        "val_df = apply_preprocess3_val(val_df, scaler_dict)"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "9h5xSZxbqNsz"
      },
      "source": [
        "split into dfs with SEQ_LEN rows"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "31jTXjddn04r",
        "outputId": "125ce716-fa5f-4839-fabe-15765768da3e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "splitDf\n",
            "-done\n",
            "\n",
            "\n",
            "splitDf\n",
            "-done\n",
            "\n"
          ]
        }
      ],
      "source": [
        "train_dfs = splitDf_new(train_df)\n",
        "val_dfs = splitDf_new(val_df)"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "Lo4KSJOxrAN0"
      },
      "source": [
        "balance buys/sells/holds"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "before balancing:\n",
            "buys: 104849 , sells: 101730 , holds: 87752\n",
            "before balancing:\n",
            "buys: 24630 , sells: 24825 , holds: 24060\n"
          ]
        }
      ],
      "source": [
        "# balance buys, sells, and holds\n",
        "import random\n",
        "\n",
        "random.shuffle(train_dfs)\n",
        "random.shuffle(val_dfs)\n",
        "train_dfs = balance(train_dfs)\n",
        "val_dfs = balance(val_dfs)\n",
        "random.shuffle(train_dfs)\n",
        "random.shuffle(val_dfs)"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "JleCIrlUs98K"
      },
      "source": [
        "build sequences"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "GToeQJ4Us_ll"
      },
      "outputs": [],
      "source": [
        "sequencesTraining = buildSequences(train_dfs)\n",
        "sequencesValidation = buildSequences(val_dfs)\n",
        "random.shuffle(sequencesTraining)\n",
        "random.shuffle(sequencesValidation)"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "G-ygYD9gtbMx"
      },
      "source": [
        "split sequence from label"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "3Cnkgt0utXt1"
      },
      "outputs": [],
      "source": [
        "train_x, train_y = xySplit(sequencesTraining)\n",
        "validation_x, validation_y = xySplit(sequencesValidation)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "<class 'numpy.ndarray'>\n",
            "(263256, 180, 6)\n",
            "<class 'numpy.ndarray'>\n",
            "(72180, 180, 6)\n"
          ]
        }
      ],
      "source": [
        "print(type(train_x))\n",
        "print(train_x.shape)\n",
        "print(type(validation_x))\n",
        "print(validation_x.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {},
      "outputs": [],
      "source": [
        "import pickle\n",
        "\n",
        "with open(f'../trainData/{NAME}_train_x.pkl', 'wb') as file:\n",
        "    pickle.dump(train_x, file)\n",
        "with open(f'../trainData/{NAME}_train_y.pkl', 'wb') as file:\n",
        "    pickle.dump(train_y, file)\n",
        "with open(f'../trainData/{NAME}_validation_x.pkl', 'wb') as file:\n",
        "    pickle.dump(validation_x, file)\n",
        "with open(f'../trainData/{NAME}_validation_y.pkl', 'wb') as file:\n",
        "    pickle.dump(validation_y, file)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {},
      "outputs": [],
      "source": [
        "import pickle\n",
        "\n",
        "with open(f\"../trainData/{NAME}_train_x.pkl\", \"rb\") as file:\n",
        "    train_x = pickle.load(file)\n",
        "with open(f\"../trainData/{NAME}_train_y.pkl\", \"rb\") as file:\n",
        "    train_y = pickle.load(file)\n",
        "with open(f\"../trainData/{NAME}_validation_x.pkl\", \"rb\") as file:\n",
        "    validation_x = pickle.load(file)\n",
        "with open(f\"../trainData/{NAME}_validation_y.pkl\", \"rb\") as file:\n",
        "    validation_y = pickle.load(file)"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "LXt32q1Tt39k"
      },
      "source": [
        "# Model:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Num GPUs Available:  1\n"
          ]
        }
      ],
      "source": [
        "import tensorflow as tf\n",
        "print(\"Num GPUs Available: \", len(tf.config.experimental.list_physical_devices('GPU')))\n"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "QNzTVj7Ue8Vg"
      },
      "source": [
        "hyper parameters bounds"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "mXBNmip7e7or"
      },
      "outputs": [],
      "source": [
        "EPOCHS = 120\n",
        "\n",
        "batchSize = 96\n",
        "layers = 2\n",
        "nodes = 64#256\n",
        "denseNodes = 32#128\n",
        "\n",
        "dropOut = 0.4#0.8 #0.92 #0.88\n",
        "rec_dropout = 0\n",
        "l1l2_reg = 0 #1e-5#1e-3\n",
        "\n",
        "learningRate = 0.00001\n",
        "decay = 0\n",
        "\n",
        "hp_suffix = f\"bs({batchSize})_layers({layers})_noded({nodes})_dNodes({denseNodes})_do({int(dropOut*100)}%)_recdo({rec_dropout})_l1l2({l1l2_reg})_lr({learningRate})_decay({decay})\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "XYo0LRjEg2m4"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:`period` argument is deprecated. Please use `save_freq` to specify the frequency in number of batches seen.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "c:\\Users\\Johannes\\miniconda3\\envs\\Quant\\lib\\site-packages\\keras\\optimizers\\optimizer_v2\\adam.py:114: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
            "  super().__init__(name, **kwargs)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/120\n",
            "   5/2743 [..............................] - ETA: 1:23 - loss: 1.1025 - accuracy: 0.3375 WARNING:tensorflow:Callback method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0194s vs `on_train_batch_end` time: 0.0210s). Check your callbacks.\n",
            "2740/2743 [============================>.] - ETA: 0s - loss: 1.0841 - accuracy: 0.3981"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": []
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2743/2743 [==============================] - 58s 20ms/step - loss: 1.0841 - accuracy: 0.3981 - val_loss: 1.0687 - val_accuracy: 0.4337\n",
            "Epoch 2/120\n",
            "2742/2743 [============================>.] - ETA: 0s - loss: 1.0549 - accuracy: 0.4379"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": []
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2743/2743 [==============================] - 47s 17ms/step - loss: 1.0549 - accuracy: 0.4379 - val_loss: 1.0416 - val_accuracy: 0.4615\n",
            "Epoch 3/120\n",
            "2743/2743 [==============================] - ETA: 0s - loss: 1.0413 - accuracy: 0.4442"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": []
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2743/2743 [==============================] - 47s 17ms/step - loss: 1.0413 - accuracy: 0.4442 - val_loss: 1.0334 - val_accuracy: 0.4698\n",
            "Epoch 4/120\n",
            "2740/2743 [============================>.] - ETA: 0s - loss: 1.0354 - accuracy: 0.4480"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": []
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2743/2743 [==============================] - 47s 17ms/step - loss: 1.0354 - accuracy: 0.4480 - val_loss: 1.0289 - val_accuracy: 0.4736\n",
            "Epoch 5/120\n",
            "2741/2743 [============================>.] - ETA: 0s - loss: 1.0321 - accuracy: 0.4526"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": []
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2743/2743 [==============================] - 46s 17ms/step - loss: 1.0321 - accuracy: 0.4526 - val_loss: 1.0254 - val_accuracy: 0.4753\n",
            "Epoch 6/120\n",
            "2743/2743 [==============================] - ETA: 0s - loss: 1.0282 - accuracy: 0.4556"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": []
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2743/2743 [==============================] - 47s 17ms/step - loss: 1.0282 - accuracy: 0.4556 - val_loss: 1.0222 - val_accuracy: 0.4772\n",
            "Epoch 7/120\n",
            "2743/2743 [==============================] - ETA: 0s - loss: 1.0252 - accuracy: 0.4573"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": []
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2743/2743 [==============================] - 48s 17ms/step - loss: 1.0252 - accuracy: 0.4573 - val_loss: 1.0191 - val_accuracy: 0.4788\n",
            "Epoch 8/120\n",
            "2743/2743 [==============================] - ETA: 0s - loss: 1.0226 - accuracy: 0.4585"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": []
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2743/2743 [==============================] - 47s 17ms/step - loss: 1.0226 - accuracy: 0.4585 - val_loss: 1.0163 - val_accuracy: 0.4807\n",
            "Epoch 9/120\n",
            "2740/2743 [============================>.] - ETA: 0s - loss: 1.0204 - accuracy: 0.4605"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": []
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2743/2743 [==============================] - 47s 17ms/step - loss: 1.0204 - accuracy: 0.4605 - val_loss: 1.0145 - val_accuracy: 0.4810\n",
            "Epoch 10/120\n",
            "2740/2743 [============================>.] - ETA: 0s - loss: 1.0186 - accuracy: 0.4607"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": []
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2743/2743 [==============================] - 47s 17ms/step - loss: 1.0185 - accuracy: 0.4608 - val_loss: 1.0129 - val_accuracy: 0.4818\n",
            "Epoch 11/120\n",
            "2742/2743 [============================>.] - ETA: 0s - loss: 1.0170 - accuracy: 0.4626"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": []
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2743/2743 [==============================] - 47s 17ms/step - loss: 1.0170 - accuracy: 0.4626 - val_loss: 1.0118 - val_accuracy: 0.4821\n",
            "Epoch 12/120\n",
            "2742/2743 [============================>.] - ETA: 0s - loss: 1.0154 - accuracy: 0.4633"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": []
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2743/2743 [==============================] - 47s 17ms/step - loss: 1.0154 - accuracy: 0.4633 - val_loss: 1.0111 - val_accuracy: 0.4821\n",
            "Epoch 13/120\n",
            "2742/2743 [============================>.] - ETA: 0s - loss: 1.0145 - accuracy: 0.4640"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": []
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2743/2743 [==============================] - 47s 17ms/step - loss: 1.0145 - accuracy: 0.4640 - val_loss: 1.0102 - val_accuracy: 0.4833\n",
            "Epoch 14/120\n",
            "2743/2743 [==============================] - ETA: 0s - loss: 1.0133 - accuracy: 0.4644"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": []
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2743/2743 [==============================] - 47s 17ms/step - loss: 1.0133 - accuracy: 0.4644 - val_loss: 1.0094 - val_accuracy: 0.4834\n",
            "Epoch 15/120\n",
            "2743/2743 [==============================] - ETA: 0s - loss: 1.0123 - accuracy: 0.4655"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": []
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2743/2743 [==============================] - 47s 17ms/step - loss: 1.0123 - accuracy: 0.4655 - val_loss: 1.0089 - val_accuracy: 0.4838\n",
            "Epoch 16/120\n",
            "2740/2743 [============================>.] - ETA: 0s - loss: 1.0117 - accuracy: 0.4665"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": []
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2743/2743 [==============================] - 47s 17ms/step - loss: 1.0117 - accuracy: 0.4664 - val_loss: 1.0081 - val_accuracy: 0.4833\n",
            "Epoch 17/120\n",
            "2742/2743 [============================>.] - ETA: 0s - loss: 1.0107 - accuracy: 0.4669"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": []
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2743/2743 [==============================] - 47s 17ms/step - loss: 1.0107 - accuracy: 0.4669 - val_loss: 1.0077 - val_accuracy: 0.4842\n",
            "Epoch 18/120\n",
            "2740/2743 [============================>.] - ETA: 0s - loss: 1.0096 - accuracy: 0.4684"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": []
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2743/2743 [==============================] - 56s 21ms/step - loss: 1.0096 - accuracy: 0.4684 - val_loss: 1.0069 - val_accuracy: 0.4846\n",
            "Epoch 19/120\n",
            "2741/2743 [============================>.] - ETA: 0s - loss: 1.0093 - accuracy: 0.4677"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": []
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2743/2743 [==============================] - 47s 17ms/step - loss: 1.0093 - accuracy: 0.4677 - val_loss: 1.0063 - val_accuracy: 0.4845\n",
            "Epoch 20/120\n",
            "2741/2743 [============================>.] - ETA: 0s - loss: 1.0085 - accuracy: 0.4692"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": []
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2743/2743 [==============================] - 55s 20ms/step - loss: 1.0085 - accuracy: 0.4692 - val_loss: 1.0061 - val_accuracy: 0.4847\n",
            "Epoch 21/120\n",
            "2740/2743 [============================>.] - ETA: 0s - loss: 1.0075 - accuracy: 0.4696"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": []
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2743/2743 [==============================] - 49s 18ms/step - loss: 1.0075 - accuracy: 0.4696 - val_loss: 1.0057 - val_accuracy: 0.4854\n",
            "Epoch 22/120\n",
            "2743/2743 [==============================] - ETA: 0s - loss: 1.0073 - accuracy: 0.4692"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": []
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2743/2743 [==============================] - 47s 17ms/step - loss: 1.0073 - accuracy: 0.4692 - val_loss: 1.0051 - val_accuracy: 0.4843\n",
            "Epoch 23/120\n",
            "2741/2743 [============================>.] - ETA: 0s - loss: 1.0059 - accuracy: 0.4706"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": []
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2743/2743 [==============================] - 47s 17ms/step - loss: 1.0059 - accuracy: 0.4706 - val_loss: 1.0046 - val_accuracy: 0.4845\n",
            "Epoch 24/120\n",
            "2742/2743 [============================>.] - ETA: 0s - loss: 1.0060 - accuracy: 0.4704"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": []
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2743/2743 [==============================] - 59s 21ms/step - loss: 1.0060 - accuracy: 0.4705 - val_loss: 1.0046 - val_accuracy: 0.4847\n",
            "Epoch 25/120\n",
            "2741/2743 [============================>.] - ETA: 0s - loss: 1.0054 - accuracy: 0.4716"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": []
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2743/2743 [==============================] - 48s 18ms/step - loss: 1.0054 - accuracy: 0.4716 - val_loss: 1.0043 - val_accuracy: 0.4847\n",
            "Epoch 26/120\n",
            "2740/2743 [============================>.] - ETA: 0s - loss: 1.0049 - accuracy: 0.4714"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": []
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2743/2743 [==============================] - 47s 17ms/step - loss: 1.0049 - accuracy: 0.4714 - val_loss: 1.0042 - val_accuracy: 0.4844\n",
            "Epoch 27/120\n",
            "2742/2743 [============================>.] - ETA: 0s - loss: 1.0046 - accuracy: 0.4718"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": []
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2743/2743 [==============================] - 48s 17ms/step - loss: 1.0046 - accuracy: 0.4718 - val_loss: 1.0037 - val_accuracy: 0.4848\n",
            "Epoch 28/120\n",
            "2741/2743 [============================>.] - ETA: 0s - loss: 1.0036 - accuracy: 0.4727"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": []
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2743/2743 [==============================] - 59s 22ms/step - loss: 1.0036 - accuracy: 0.4727 - val_loss: 1.0034 - val_accuracy: 0.4849\n",
            "Epoch 29/120\n",
            "2742/2743 [============================>.] - ETA: 0s - loss: 1.0030 - accuracy: 0.4732"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": []
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2743/2743 [==============================] - 46s 17ms/step - loss: 1.0030 - accuracy: 0.4732 - val_loss: 1.0032 - val_accuracy: 0.4850\n",
            "Epoch 30/120\n",
            "2741/2743 [============================>.] - ETA: 0s - loss: 1.0029 - accuracy: 0.4742"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": []
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2743/2743 [==============================] - 46s 17ms/step - loss: 1.0029 - accuracy: 0.4742 - val_loss: 1.0030 - val_accuracy: 0.4851\n",
            "Epoch 31/120\n",
            "2742/2743 [============================>.] - ETA: 0s - loss: 1.0024 - accuracy: 0.4739"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": []
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2743/2743 [==============================] - 45s 17ms/step - loss: 1.0024 - accuracy: 0.4739 - val_loss: 1.0027 - val_accuracy: 0.4848\n",
            "Epoch 32/120\n",
            "2743/2743 [==============================] - ETA: 0s - loss: 1.0019 - accuracy: 0.4736"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": []
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2743/2743 [==============================] - 56s 20ms/step - loss: 1.0019 - accuracy: 0.4736 - val_loss: 1.0025 - val_accuracy: 0.4846\n",
            "Epoch 33/120\n",
            "2743/2743 [==============================] - ETA: 0s - loss: 1.0022 - accuracy: 0.4738"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": []
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2743/2743 [==============================] - 51s 19ms/step - loss: 1.0022 - accuracy: 0.4738 - val_loss: 1.0025 - val_accuracy: 0.4854\n",
            "Epoch 34/120\n",
            "2741/2743 [============================>.] - ETA: 0s - loss: 1.0009 - accuracy: 0.4748"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": []
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2743/2743 [==============================] - 57s 21ms/step - loss: 1.0009 - accuracy: 0.4748 - val_loss: 1.0023 - val_accuracy: 0.4843\n",
            "Epoch 35/120\n",
            "2741/2743 [============================>.] - ETA: 0s - loss: 1.0006 - accuracy: 0.4748"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": []
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2743/2743 [==============================] - 54s 20ms/step - loss: 1.0006 - accuracy: 0.4748 - val_loss: 1.0021 - val_accuracy: 0.4853\n",
            "Epoch 36/120\n",
            "2743/2743 [==============================] - ETA: 0s - loss: 1.0006 - accuracy: 0.4761"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": []
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2743/2743 [==============================] - 47s 17ms/step - loss: 1.0006 - accuracy: 0.4761 - val_loss: 1.0021 - val_accuracy: 0.4846\n",
            "Epoch 37/120\n",
            "2741/2743 [============================>.] - ETA: 0s - loss: 1.0004 - accuracy: 0.4757"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": []
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2743/2743 [==============================] - 48s 18ms/step - loss: 1.0004 - accuracy: 0.4757 - val_loss: 1.0021 - val_accuracy: 0.4842\n",
            "Epoch 38/120\n",
            "2741/2743 [============================>.] - ETA: 0s - loss: 1.0002 - accuracy: 0.4762"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": []
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2743/2743 [==============================] - 55s 20ms/step - loss: 1.0002 - accuracy: 0.4762 - val_loss: 1.0019 - val_accuracy: 0.4843\n",
            "Epoch 39/120\n",
            "2741/2743 [============================>.] - ETA: 0s - loss: 0.9999 - accuracy: 0.4758"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": []
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2743/2743 [==============================] - 46s 17ms/step - loss: 0.9999 - accuracy: 0.4759 - val_loss: 1.0016 - val_accuracy: 0.4847\n",
            "Epoch 40/120\n",
            "2743/2743 [==============================] - ETA: 0s - loss: 0.9996 - accuracy: 0.4760"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": []
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2743/2743 [==============================] - 46s 17ms/step - loss: 0.9996 - accuracy: 0.4760 - val_loss: 1.0015 - val_accuracy: 0.4854\n",
            "Epoch 41/120\n",
            "2741/2743 [============================>.] - ETA: 0s - loss: 0.9987 - accuracy: 0.4765"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": []
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2743/2743 [==============================] - 51s 19ms/step - loss: 0.9987 - accuracy: 0.4765 - val_loss: 1.0014 - val_accuracy: 0.4847\n",
            "Epoch 42/120\n",
            "2740/2743 [============================>.] - ETA: 0s - loss: 0.9988 - accuracy: 0.4760"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": []
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2743/2743 [==============================] - 46s 17ms/step - loss: 0.9988 - accuracy: 0.4760 - val_loss: 1.0012 - val_accuracy: 0.4845\n",
            "Epoch 43/120\n",
            "2740/2743 [============================>.] - ETA: 0s - loss: 0.9985 - accuracy: 0.4767"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": []
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2743/2743 [==============================] - 46s 17ms/step - loss: 0.9985 - accuracy: 0.4767 - val_loss: 1.0012 - val_accuracy: 0.4851\n",
            "Epoch 44/120\n",
            "2742/2743 [============================>.] - ETA: 0s - loss: 0.9983 - accuracy: 0.4771"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": []
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2743/2743 [==============================] - 49s 18ms/step - loss: 0.9983 - accuracy: 0.4771 - val_loss: 1.0012 - val_accuracy: 0.4844\n",
            "Epoch 45/120\n",
            "2741/2743 [============================>.] - ETA: 0s - loss: 0.9974 - accuracy: 0.4773"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": []
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2743/2743 [==============================] - 47s 17ms/step - loss: 0.9974 - accuracy: 0.4772 - val_loss: 1.0010 - val_accuracy: 0.4844\n",
            "Epoch 46/120\n",
            "2742/2743 [============================>.] - ETA: 0s - loss: 0.9978 - accuracy: 0.4774"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": []
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2743/2743 [==============================] - 47s 17ms/step - loss: 0.9978 - accuracy: 0.4774 - val_loss: 1.0009 - val_accuracy: 0.4845\n",
            "Epoch 47/120\n",
            "2740/2743 [============================>.] - ETA: 0s - loss: 0.9979 - accuracy: 0.4769"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": []
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2743/2743 [==============================] - 58s 21ms/step - loss: 0.9979 - accuracy: 0.4768 - val_loss: 1.0008 - val_accuracy: 0.4846\n",
            "Epoch 48/120\n",
            "2742/2743 [============================>.] - ETA: 0s - loss: 0.9971 - accuracy: 0.4779"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": []
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2743/2743 [==============================] - 46s 17ms/step - loss: 0.9971 - accuracy: 0.4779 - val_loss: 1.0006 - val_accuracy: 0.4844\n",
            "Epoch 49/120\n",
            "2740/2743 [============================>.] - ETA: 0s - loss: 0.9967 - accuracy: 0.4782"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": []
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2743/2743 [==============================] - 48s 17ms/step - loss: 0.9967 - accuracy: 0.4781 - val_loss: 1.0004 - val_accuracy: 0.4844\n",
            "Epoch 50/120\n",
            "2740/2743 [============================>.] - ETA: 0s - loss: 0.9965 - accuracy: 0.4786"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": []
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2743/2743 [==============================] - 46s 17ms/step - loss: 0.9965 - accuracy: 0.4786 - val_loss: 1.0005 - val_accuracy: 0.4837\n",
            "Epoch 51/120\n",
            "2742/2743 [============================>.] - ETA: 0s - loss: 0.9965 - accuracy: 0.4785"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": []
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2743/2743 [==============================] - 46s 17ms/step - loss: 0.9965 - accuracy: 0.4785 - val_loss: 1.0006 - val_accuracy: 0.4841\n",
            "Epoch 52/120\n",
            "2061/2743 [=====================>........] - ETA: 10s - loss: 0.9966 - accuracy: 0.4773"
          ]
        },
        {
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[1;32mc:\\Users\\Johannes\\Desktop\\PythonProjects\\QuantShit\\python-crypto-ai\\model3_pp3\\modelTrainPreClassified_pp3.ipynb Cell 33\u001b[0m line \u001b[0;36m8\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/Johannes/Desktop/PythonProjects/QuantShit/python-crypto-ai/model3_pp3/modelTrainPreClassified_pp3.ipynb#X44sZmlsZQ%3D%3D?line=82'>83</a>\u001b[0m     json\u001b[39m.\u001b[39mdump(data, json_file, indent\u001b[39m=\u001b[39m\u001b[39m4\u001b[39m)\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/Johannes/Desktop/PythonProjects/QuantShit/python-crypto-ai/model3_pp3/modelTrainPreClassified_pp3.ipynb#X44sZmlsZQ%3D%3D?line=87'>88</a>\u001b[0m \u001b[39m# train\u001b[39;00m\n\u001b[1;32m---> <a href='vscode-notebook-cell:/c%3A/Users/Johannes/Desktop/PythonProjects/QuantShit/python-crypto-ai/model3_pp3/modelTrainPreClassified_pp3.ipynb#X44sZmlsZQ%3D%3D?line=88'>89</a>\u001b[0m history \u001b[39m=\u001b[39m model\u001b[39m.\u001b[39;49mfit(\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/Johannes/Desktop/PythonProjects/QuantShit/python-crypto-ai/model3_pp3/modelTrainPreClassified_pp3.ipynb#X44sZmlsZQ%3D%3D?line=89'>90</a>\u001b[0m   train_x, train_y,\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/Johannes/Desktop/PythonProjects/QuantShit/python-crypto-ai/model3_pp3/modelTrainPreClassified_pp3.ipynb#X44sZmlsZQ%3D%3D?line=90'>91</a>\u001b[0m   batch_size \u001b[39m=\u001b[39;49m batchSize,\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/Johannes/Desktop/PythonProjects/QuantShit/python-crypto-ai/model3_pp3/modelTrainPreClassified_pp3.ipynb#X44sZmlsZQ%3D%3D?line=91'>92</a>\u001b[0m   epochs \u001b[39m=\u001b[39;49m EPOCHS,\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/Johannes/Desktop/PythonProjects/QuantShit/python-crypto-ai/model3_pp3/modelTrainPreClassified_pp3.ipynb#X44sZmlsZQ%3D%3D?line=92'>93</a>\u001b[0m   validation_data\u001b[39m=\u001b[39;49m(validation_x, validation_y),\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/Johannes/Desktop/PythonProjects/QuantShit/python-crypto-ai/model3_pp3/modelTrainPreClassified_pp3.ipynb#X44sZmlsZQ%3D%3D?line=93'>94</a>\u001b[0m   callbacks\u001b[39m=\u001b[39;49m[checkpoint, TqdmCallback(verbose\u001b[39m=\u001b[39;49m\u001b[39m0\u001b[39;49m), tensorboard_callback])\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/Johannes/Desktop/PythonProjects/QuantShit/python-crypto-ai/model3_pp3/modelTrainPreClassified_pp3.ipynb#X44sZmlsZQ%3D%3D?line=94'>95</a>\u001b[0m   \u001b[39m#callbacks=[checkpoint])\u001b[39;00m\n",
            "File \u001b[1;32mc:\\Users\\Johannes\\miniconda3\\envs\\Quant\\lib\\site-packages\\keras\\utils\\traceback_utils.py:65\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     63\u001b[0m filtered_tb \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n\u001b[0;32m     64\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m---> 65\u001b[0m     \u001b[39mreturn\u001b[39;00m fn(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m     66\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m \u001b[39mas\u001b[39;00m e:\n\u001b[0;32m     67\u001b[0m     filtered_tb \u001b[39m=\u001b[39m _process_traceback_frames(e\u001b[39m.\u001b[39m__traceback__)\n",
            "File \u001b[1;32mc:\\Users\\Johannes\\miniconda3\\envs\\Quant\\lib\\site-packages\\keras\\engine\\training.py:1564\u001b[0m, in \u001b[0;36mModel.fit\u001b[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[0;32m   1556\u001b[0m \u001b[39mwith\u001b[39;00m tf\u001b[39m.\u001b[39mprofiler\u001b[39m.\u001b[39mexperimental\u001b[39m.\u001b[39mTrace(\n\u001b[0;32m   1557\u001b[0m     \u001b[39m\"\u001b[39m\u001b[39mtrain\u001b[39m\u001b[39m\"\u001b[39m,\n\u001b[0;32m   1558\u001b[0m     epoch_num\u001b[39m=\u001b[39mepoch,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1561\u001b[0m     _r\u001b[39m=\u001b[39m\u001b[39m1\u001b[39m,\n\u001b[0;32m   1562\u001b[0m ):\n\u001b[0;32m   1563\u001b[0m     callbacks\u001b[39m.\u001b[39mon_train_batch_begin(step)\n\u001b[1;32m-> 1564\u001b[0m     tmp_logs \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mtrain_function(iterator)\n\u001b[0;32m   1565\u001b[0m     \u001b[39mif\u001b[39;00m data_handler\u001b[39m.\u001b[39mshould_sync:\n\u001b[0;32m   1566\u001b[0m         context\u001b[39m.\u001b[39masync_wait()\n",
            "File \u001b[1;32mc:\\Users\\Johannes\\miniconda3\\envs\\Quant\\lib\\site-packages\\tensorflow\\python\\util\\traceback_utils.py:150\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    148\u001b[0m filtered_tb \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n\u001b[0;32m    149\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m--> 150\u001b[0m   \u001b[39mreturn\u001b[39;00m fn(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m    151\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m \u001b[39mas\u001b[39;00m e:\n\u001b[0;32m    152\u001b[0m   filtered_tb \u001b[39m=\u001b[39m _process_traceback_frames(e\u001b[39m.\u001b[39m__traceback__)\n",
            "File \u001b[1;32mc:\\Users\\Johannes\\miniconda3\\envs\\Quant\\lib\\site-packages\\tensorflow\\python\\eager\\def_function.py:915\u001b[0m, in \u001b[0;36mFunction.__call__\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    912\u001b[0m compiler \u001b[39m=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mxla\u001b[39m\u001b[39m\"\u001b[39m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_jit_compile \u001b[39melse\u001b[39;00m \u001b[39m\"\u001b[39m\u001b[39mnonXla\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    914\u001b[0m \u001b[39mwith\u001b[39;00m OptionalXlaContext(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_jit_compile):\n\u001b[1;32m--> 915\u001b[0m   result \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_call(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwds)\n\u001b[0;32m    917\u001b[0m new_tracing_count \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mexperimental_get_tracing_count()\n\u001b[0;32m    918\u001b[0m without_tracing \u001b[39m=\u001b[39m (tracing_count \u001b[39m==\u001b[39m new_tracing_count)\n",
            "File \u001b[1;32mc:\\Users\\Johannes\\miniconda3\\envs\\Quant\\lib\\site-packages\\tensorflow\\python\\eager\\def_function.py:947\u001b[0m, in \u001b[0;36mFunction._call\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    944\u001b[0m   \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_lock\u001b[39m.\u001b[39mrelease()\n\u001b[0;32m    945\u001b[0m   \u001b[39m# In this case we have created variables on the first call, so we run the\u001b[39;00m\n\u001b[0;32m    946\u001b[0m   \u001b[39m# defunned version which is guaranteed to never create variables.\u001b[39;00m\n\u001b[1;32m--> 947\u001b[0m   \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_stateless_fn(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwds)  \u001b[39m# pylint: disable=not-callable\u001b[39;00m\n\u001b[0;32m    948\u001b[0m \u001b[39melif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_stateful_fn \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m    949\u001b[0m   \u001b[39m# Release the lock early so that multiple threads can perform the call\u001b[39;00m\n\u001b[0;32m    950\u001b[0m   \u001b[39m# in parallel.\u001b[39;00m\n\u001b[0;32m    951\u001b[0m   \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_lock\u001b[39m.\u001b[39mrelease()\n",
            "File \u001b[1;32mc:\\Users\\Johannes\\miniconda3\\envs\\Quant\\lib\\site-packages\\tensorflow\\python\\eager\\function.py:2496\u001b[0m, in \u001b[0;36mFunction.__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   2493\u001b[0m \u001b[39mwith\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_lock:\n\u001b[0;32m   2494\u001b[0m   (graph_function,\n\u001b[0;32m   2495\u001b[0m    filtered_flat_args) \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_maybe_define_function(args, kwargs)\n\u001b[1;32m-> 2496\u001b[0m \u001b[39mreturn\u001b[39;00m graph_function\u001b[39m.\u001b[39;49m_call_flat(\n\u001b[0;32m   2497\u001b[0m     filtered_flat_args, captured_inputs\u001b[39m=\u001b[39;49mgraph_function\u001b[39m.\u001b[39;49mcaptured_inputs)\n",
            "File \u001b[1;32mc:\\Users\\Johannes\\miniconda3\\envs\\Quant\\lib\\site-packages\\tensorflow\\python\\eager\\function.py:1862\u001b[0m, in \u001b[0;36mConcreteFunction._call_flat\u001b[1;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[0;32m   1858\u001b[0m possible_gradient_type \u001b[39m=\u001b[39m gradients_util\u001b[39m.\u001b[39mPossibleTapeGradientTypes(args)\n\u001b[0;32m   1859\u001b[0m \u001b[39mif\u001b[39;00m (possible_gradient_type \u001b[39m==\u001b[39m gradients_util\u001b[39m.\u001b[39mPOSSIBLE_GRADIENT_TYPES_NONE\n\u001b[0;32m   1860\u001b[0m     \u001b[39mand\u001b[39;00m executing_eagerly):\n\u001b[0;32m   1861\u001b[0m   \u001b[39m# No tape is watching; skip to running the function.\u001b[39;00m\n\u001b[1;32m-> 1862\u001b[0m   \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_build_call_outputs(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_inference_function\u001b[39m.\u001b[39;49mcall(\n\u001b[0;32m   1863\u001b[0m       ctx, args, cancellation_manager\u001b[39m=\u001b[39;49mcancellation_manager))\n\u001b[0;32m   1864\u001b[0m forward_backward \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_select_forward_and_backward_functions(\n\u001b[0;32m   1865\u001b[0m     args,\n\u001b[0;32m   1866\u001b[0m     possible_gradient_type,\n\u001b[0;32m   1867\u001b[0m     executing_eagerly)\n\u001b[0;32m   1868\u001b[0m forward_function, args_with_tangents \u001b[39m=\u001b[39m forward_backward\u001b[39m.\u001b[39mforward()\n",
            "File \u001b[1;32mc:\\Users\\Johannes\\miniconda3\\envs\\Quant\\lib\\site-packages\\tensorflow\\python\\eager\\function.py:499\u001b[0m, in \u001b[0;36m_EagerDefinedFunction.call\u001b[1;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[0;32m    497\u001b[0m \u001b[39mwith\u001b[39;00m _InterpolateFunctionError(\u001b[39mself\u001b[39m):\n\u001b[0;32m    498\u001b[0m   \u001b[39mif\u001b[39;00m cancellation_manager \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m--> 499\u001b[0m     outputs \u001b[39m=\u001b[39m execute\u001b[39m.\u001b[39;49mexecute(\n\u001b[0;32m    500\u001b[0m         \u001b[39mstr\u001b[39;49m(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49msignature\u001b[39m.\u001b[39;49mname),\n\u001b[0;32m    501\u001b[0m         num_outputs\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_num_outputs,\n\u001b[0;32m    502\u001b[0m         inputs\u001b[39m=\u001b[39;49margs,\n\u001b[0;32m    503\u001b[0m         attrs\u001b[39m=\u001b[39;49mattrs,\n\u001b[0;32m    504\u001b[0m         ctx\u001b[39m=\u001b[39;49mctx)\n\u001b[0;32m    505\u001b[0m   \u001b[39melse\u001b[39;00m:\n\u001b[0;32m    506\u001b[0m     outputs \u001b[39m=\u001b[39m execute\u001b[39m.\u001b[39mexecute_with_cancellation(\n\u001b[0;32m    507\u001b[0m         \u001b[39mstr\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39msignature\u001b[39m.\u001b[39mname),\n\u001b[0;32m    508\u001b[0m         num_outputs\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_num_outputs,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    511\u001b[0m         ctx\u001b[39m=\u001b[39mctx,\n\u001b[0;32m    512\u001b[0m         cancellation_manager\u001b[39m=\u001b[39mcancellation_manager)\n",
            "File \u001b[1;32mc:\\Users\\Johannes\\miniconda3\\envs\\Quant\\lib\\site-packages\\tensorflow\\python\\eager\\execute.py:54\u001b[0m, in \u001b[0;36mquick_execute\u001b[1;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[0;32m     52\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m     53\u001b[0m   ctx\u001b[39m.\u001b[39mensure_initialized()\n\u001b[1;32m---> 54\u001b[0m   tensors \u001b[39m=\u001b[39m pywrap_tfe\u001b[39m.\u001b[39;49mTFE_Py_Execute(ctx\u001b[39m.\u001b[39;49m_handle, device_name, op_name,\n\u001b[0;32m     55\u001b[0m                                       inputs, attrs, num_outputs)\n\u001b[0;32m     56\u001b[0m \u001b[39mexcept\u001b[39;00m core\u001b[39m.\u001b[39m_NotOkStatusException \u001b[39mas\u001b[39;00m e:\n\u001b[0;32m     57\u001b[0m   \u001b[39mif\u001b[39;00m name \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n",
            "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ],
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense, Dropout, LSTM, BatchNormalization\n",
        "from tensorflow.keras.callbacks import ModelCheckpoint, TensorBoard\n",
        "import os\n",
        "from tqdm.keras import TqdmCallback\n",
        "import datetime\n",
        "from tensorflow.keras.layers import Bidirectional\n",
        "from tensorflow.keras import regularizers\n",
        "import json\n",
        "# model\n",
        "model = Sequential()\n",
        "\n",
        "for _ in range(layers-1):\n",
        "  model.add(LSTM(nodes, \n",
        "               activation=\"tanh\", \n",
        "               recurrent_activation = 'sigmoid', \n",
        "               recurrent_dropout = rec_dropout, \n",
        "               unroll = False, \n",
        "               use_bias = True, \n",
        "               input_shape=(train_x.shape[1:]), \n",
        "               return_sequences=True,\n",
        "               kernel_regularizer=regularizers.l1_l2(l1=l1l2_reg/10, l2=l1l2_reg),\n",
        "               #bias_regularizer=regularizers.l2(l1l2_reg),\n",
        "               activity_regularizer=regularizers.l2(l1l2_reg)\n",
        "               ))\n",
        "  model.add(Dropout(dropOut))\n",
        "  #model.add(BatchNormalization())\n",
        "\n",
        "model.add(LSTM(nodes, \n",
        "             activation=\"tanh\", \n",
        "             recurrent_activation = 'sigmoid', \n",
        "             recurrent_dropout = rec_dropout, \n",
        "             unroll = False, \n",
        "             use_bias = True, \n",
        "             input_shape=(train_x.shape[1:]),\n",
        "             kernel_regularizer=regularizers.l1_l2(l1=l1l2_reg/10, l2=l1l2_reg),\n",
        "             #bias_regularizer=regularizers.l2(l1l2_reg),\n",
        "             activity_regularizer=regularizers.l2(l1l2_reg)\n",
        "             ))\n",
        "model.add(Dropout(dropOut))\n",
        "#model.add(BatchNormalization())\n",
        "\n",
        "model.add(Dense(denseNodes, \n",
        "                activation=\"relu\",\n",
        "                kernel_regularizer=regularizers.l1_l2(l1=l1l2_reg/10, l2=l1l2_reg),\n",
        "                #bias_regularizer=regularizers.l2(l1l2_reg), \n",
        "                activity_regularizer=regularizers.l2(l1l2_reg)))\n",
        "model.add(Dropout(dropOut))\n",
        "\n",
        "model.add(Dense(3, activation=\"softmax\"))\n",
        "\n",
        "\n",
        "\n",
        "# opt  \n",
        "opt = tf.keras.optimizers.Adam(lr=learningRate) # decay?\n",
        "\n",
        "\n",
        "model.compile(loss=\"sparse_categorical_crossentropy\",\n",
        "              optimizer = opt,\n",
        "              metrics=[\"accuracy\"])\n",
        "\n",
        "\n",
        "filename = \"\" + NAME + \"-{epoch:02d}\"\n",
        "filepath = f\"models/{filename}.h5\"\n",
        "checkpoint = ModelCheckpoint(filepath, monitor='val_loss', verbose=0, save_best_only=False, save_weights_only=False, mode='auto', period=1) # saves every epoch\n",
        "\n",
        "# Prepare TensorBoard callback\n",
        "log_dir = \"../logs/fit/\" + f\"{NAME}\" + datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\")\n",
        "tensorboard_callback = TensorBoard(log_dir=log_dir, histogram_freq=1)\n",
        "\n",
        "\n",
        "# store hyper-parameters\n",
        "# Path to the JSON file\n",
        "file_path = \"models/hps/hps.json\"\n",
        "# Load the JSON file into a dictionary\n",
        "with open(file_path, \"r\") as json_file:\n",
        "    data = json.load(json_file)\n",
        "# Add a new key-value pair to the dictionary\n",
        "data[f\"{NAME}\" + datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\")] = hp_suffix\n",
        "# Write the updated dictionary back to the file\n",
        "with open(file_path, \"w\") as json_file:\n",
        "    json.dump(data, json_file, indent=4)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "# train\n",
        "history = model.fit(\n",
        "  train_x, train_y,\n",
        "  batch_size = batchSize,\n",
        "  epochs = EPOCHS,\n",
        "  validation_data=(validation_x, validation_y),\n",
        "  callbacks=[checkpoint, TqdmCallback(verbose=0), tensorboard_callback])\n",
        "  #callbacks=[checkpoint])"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [],
      "machine_shape": "hm",
      "name": "modelTrainPreClassified.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.12"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}

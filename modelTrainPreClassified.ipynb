{
  "cells": [
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "M7KYj8EtoPxZ"
      },
      "source": [
        "# Constants:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "ZsusFSopoVfn"
      },
      "outputs": [],
      "source": [
        "SEQ_LEN = 240   # how many past candles to use to predict\n",
        "CANDLES_SHIFT = 1 # how many candles to shift between sequences\n",
        "NAME = \"r40t075\"\n",
        "VALIDATION_PCT = 0.2"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "Zspc4aD1juaP"
      },
      "source": [
        "DF initialisation:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 402
        },
        "id": "KfSNaRUgirE3",
        "outputId": "e9f3c791-099e-496a-9b0d-7aa70dfe4a48"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>BTC_close</th>\n",
              "      <th>BTC_low</th>\n",
              "      <th>BTC_high</th>\n",
              "      <th>BTC_volume</th>\n",
              "      <th>BTC_average</th>\n",
              "      <th>BTC_HLPercent</th>\n",
              "      <th>target</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>675.50</td>\n",
              "      <td>671.00</td>\n",
              "      <td>675.50</td>\n",
              "      <td>0.0001</td>\n",
              "      <td>674.66</td>\n",
              "      <td>0.006662</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>667.00</td>\n",
              "      <td>667.00</td>\n",
              "      <td>671.00</td>\n",
              "      <td>2764.2000</td>\n",
              "      <td>668.04</td>\n",
              "      <td>0.005961</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>670.10</td>\n",
              "      <td>670.10</td>\n",
              "      <td>671.99</td>\n",
              "      <td>8873.0000</td>\n",
              "      <td>671.99</td>\n",
              "      <td>0.002813</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>667.00</td>\n",
              "      <td>667.00</td>\n",
              "      <td>672.00</td>\n",
              "      <td>204.4600</td>\n",
              "      <td>671.90</td>\n",
              "      <td>0.007440</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>667.00</td>\n",
              "      <td>667.00</td>\n",
              "      <td>672.00</td>\n",
              "      <td>0.0001</td>\n",
              "      <td>671.90</td>\n",
              "      <td>0.007440</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>711758</th>\n",
              "      <td>28423.92</td>\n",
              "      <td>28416.67</td>\n",
              "      <td>28440.89</td>\n",
              "      <td>4032.0000</td>\n",
              "      <td>28424.22</td>\n",
              "      <td>0.000852</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>711759</th>\n",
              "      <td>28402.64</td>\n",
              "      <td>28401.90</td>\n",
              "      <td>28426.65</td>\n",
              "      <td>1226.3600</td>\n",
              "      <td>28409.15</td>\n",
              "      <td>0.000871</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>711760</th>\n",
              "      <td>28418.48</td>\n",
              "      <td>28403.11</td>\n",
              "      <td>28418.48</td>\n",
              "      <td>4559.1800</td>\n",
              "      <td>28406.68</td>\n",
              "      <td>0.000541</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>711761</th>\n",
              "      <td>28412.62</td>\n",
              "      <td>28407.49</td>\n",
              "      <td>28422.84</td>\n",
              "      <td>388.8300</td>\n",
              "      <td>28413.01</td>\n",
              "      <td>0.000540</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>711762</th>\n",
              "      <td>28422.07</td>\n",
              "      <td>28384.76</td>\n",
              "      <td>28422.09</td>\n",
              "      <td>306.0200</td>\n",
              "      <td>28407.02</td>\n",
              "      <td>0.001313</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>711763 rows Ã— 7 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "        BTC_close   BTC_low  BTC_high  BTC_volume  BTC_average  BTC_HLPercent  \\\n",
              "0          675.50    671.00    675.50      0.0001       674.66       0.006662   \n",
              "1          667.00    667.00    671.00   2764.2000       668.04       0.005961   \n",
              "2          670.10    670.10    671.99   8873.0000       671.99       0.002813   \n",
              "3          667.00    667.00    672.00    204.4600       671.90       0.007440   \n",
              "4          667.00    667.00    672.00      0.0001       671.90       0.007440   \n",
              "...           ...       ...       ...         ...          ...            ...   \n",
              "711758   28423.92  28416.67  28440.89   4032.0000     28424.22       0.000852   \n",
              "711759   28402.64  28401.90  28426.65   1226.3600     28409.15       0.000871   \n",
              "711760   28418.48  28403.11  28418.48   4559.1800     28406.68       0.000541   \n",
              "711761   28412.62  28407.49  28422.84    388.8300     28413.01       0.000540   \n",
              "711762   28422.07  28384.76  28422.09    306.0200     28407.02       0.001313   \n",
              "\n",
              "        target  \n",
              "0            0  \n",
              "1            0  \n",
              "2            0  \n",
              "3            0  \n",
              "4            0  \n",
              "...        ...  \n",
              "711758       0  \n",
              "711759       0  \n",
              "711760       0  \n",
              "711761       0  \n",
              "711762       0  \n",
              "\n",
              "[711763 rows x 7 columns]"
            ]
          },
          "execution_count": 3,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "import pandas as pd\n",
        "main_df = pd.read_csv(\"HistoricalDataClassified_2016_2023.csv\")\n",
        "main_df"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "oSqPTNz-m5fo"
      },
      "source": [
        "# Functions:"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "1V8NN17CqWGA"
      },
      "source": [
        "split df"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "aAoFhaP8qX7P"
      },
      "outputs": [],
      "source": [
        "def splitDf(df):\n",
        "    \n",
        "    res = []\n",
        "    print(\"\")\n",
        "    print(\"splitDf\")\n",
        "    while len(df) >= SEQ_LEN + len(df.columns) -1:\n",
        "        first = df.head(SEQ_LEN + len(df.columns) -1).copy()\n",
        "        first.index = np.arange(0, len(first))\n",
        "        res.append(first)\n",
        "        df = df.tail(len(df) - CANDLES_SHIFT)\n",
        "        df.index = np.arange(0, len(df))\n",
        "\n",
        "    print(\"-done\")\n",
        "    print(\"\")\n",
        "    return res"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "v84s4MzlrJex"
      },
      "source": [
        "balance"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "Hddt3uD8rLYE"
      },
      "outputs": [],
      "source": [
        "def balance(dfs):\n",
        "    \n",
        "    buys = []\n",
        "    sells = []\n",
        "    holds = []\n",
        "    for df in dfs:\n",
        "        if df.at[len(df)-1, 'target'] == 0:\n",
        "            sells.append(df)\n",
        "        elif df.at[len(df)-1, 'target'] == 1:\n",
        "            buys.append(df)\n",
        "        else:\n",
        "          holds.append(df)\n",
        "\n",
        "    print(\"before balancing:\")\n",
        "    print(\"buys:\", len(buys), \", sells:\", len(sells), \", holds:\", len(holds))\n",
        "\n",
        "    smallest = min(len(buys), len(sells), len(holds))\n",
        "    buys = buys[:smallest]\n",
        "    sells = sells[:smallest]\n",
        "    holds = holds[:smallest]\n",
        "\n",
        "    dfsBalanced = buys+sells+holds\n",
        "    return dfsBalanced"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "puLrLHQCr2IF"
      },
      "source": [
        "preprocessing"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "HkiAmxApr4HE"
      },
      "outputs": [],
      "source": [
        "from sklearn import preprocessing\n",
        "from tqdm import tqdm\n",
        "\n",
        "def preprocess(dfs):\n",
        "    \n",
        "    for df in dfs:\n",
        "        for col in df.columns:\n",
        "            if col != \"target\":\n",
        "                df[col] = df[col].pct_change()\n",
        "                df.dropna(inplace=True)\n",
        "                df[col] = preprocessing.scale(df[col].values)\n",
        "                df.index = np.arange(0, len(df))\n",
        "\n",
        "    return dfs"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "Mtk_1EDotEdd"
      },
      "source": [
        "sequences"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "U4r2br77tGf-"
      },
      "outputs": [],
      "source": [
        "def buildSequences(dfs):\n",
        "    \n",
        "    sequences = []\n",
        "    for df in dfs:\n",
        "        if(len(df) == SEQ_LEN):\n",
        "            label = df.at[SEQ_LEN-1, 'target']\n",
        "            df = df.iloc[:, :-1]\n",
        "            dfArray = df.values.tolist()\n",
        "            sequences.append([np.array(dfArray), label])\n",
        "    \n",
        "    return sequences"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "Dd640LH1tix2"
      },
      "source": [
        "split"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "4-HIbtKAtj-0"
      },
      "outputs": [],
      "source": [
        "def split(seqWithTarget):\n",
        "\n",
        "    X = []\n",
        "    y = []\n",
        "    for seq, target in seqWithTarget:\n",
        "        X.append(seq)\n",
        "        y.append(target)\n",
        "\n",
        "    return np.array(X),np.array(y)"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "bBfc_4lKnYpv"
      },
      "source": [
        "# DF manipulation, build training sets:"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "9h5xSZxbqNsz"
      },
      "source": [
        "split into dfs with SEQ_LEN rows"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "31jTXjddn04r",
        "outputId": "125ce716-fa5f-4839-fabe-15765768da3e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "splitDf\n",
            "-done\n",
            "\n"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "splittedDfs = splitDf(main_df)"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "CdP3PNKHquOk"
      },
      "source": [
        "seperate training and validation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "NlwWOLZVqudy"
      },
      "outputs": [],
      "source": [
        "dfsTraining = splittedDfs[:(int(len(splittedDfs) * (1-VALIDATION_PCT)))].copy()\n",
        "dfsValidation = splittedDfs[(int(len(splittedDfs) * (1-VALIDATION_PCT))):].copy()"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "CU3bhQJtq1ft"
      },
      "source": [
        "shuffle"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "rhEBABokq1-I"
      },
      "outputs": [],
      "source": [
        "import random\n",
        "\n",
        "random.shuffle(dfsTraining)\n",
        "random.shuffle(dfsValidation)"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "Lo4KSJOxrAN0"
      },
      "source": [
        "balance buys/sells/holds"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GM9MzjVkq2i6",
        "outputId": "0923e1ea-7878-416b-f773-04e1ccdd4df1"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "before balancing:\n",
            "buys: 45775 , sells: 44747 , holds: 478692\n"
          ]
        }
      ],
      "source": [
        "dfsTrainingBalanced = balance(dfsTraining)\n",
        "dfsValidationBalanced = dfsValidation # balance(dfsValidation) , validation data does not have to be balanced   "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "before balancing:\n",
            "buys: 7634 , sells: 7136 , holds: 127534\n"
          ]
        }
      ],
      "source": [
        "dfsValidationBalanced = balance(dfsValidation)"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "lmvWD-1bBYVH"
      },
      "source": [
        "shuffle"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "oRUhvptlAiVi"
      },
      "outputs": [],
      "source": [
        "random.shuffle(dfsTrainingBalanced)\n",
        "random.shuffle(dfsValidationBalanced)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {},
      "outputs": [],
      "source": [
        "import pickle"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {},
      "outputs": [
        {
          "ename": "NameError",
          "evalue": "name 'pickle' is not defined",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "Cell \u001b[1;32mIn[1], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[39mwith\u001b[39;00m \u001b[39mopen\u001b[39m(\u001b[39m'\u001b[39m\u001b[39mdfsTrainingBalanced.pkl\u001b[39m\u001b[39m'\u001b[39m, \u001b[39m'\u001b[39m\u001b[39mwb\u001b[39m\u001b[39m'\u001b[39m) \u001b[39mas\u001b[39;00m file:\n\u001b[1;32m----> 2\u001b[0m     pickle\u001b[39m.\u001b[39mdump(dfsTrainingBalanced, file)\n\u001b[0;32m      3\u001b[0m \u001b[39mwith\u001b[39;00m \u001b[39mopen\u001b[39m(\u001b[39m'\u001b[39m\u001b[39mdfsValidationBalanced.pkl\u001b[39m\u001b[39m'\u001b[39m, \u001b[39m'\u001b[39m\u001b[39mwb\u001b[39m\u001b[39m'\u001b[39m) \u001b[39mas\u001b[39;00m file:\n\u001b[0;32m      4\u001b[0m     pickle\u001b[39m.\u001b[39mdump(dfsValidationBalanced, file)\n",
            "\u001b[1;31mNameError\u001b[0m: name 'pickle' is not defined"
          ]
        }
      ],
      "source": [
        "\n",
        "with open('dfsTrainingBalanced.pkl', 'wb') as file:\n",
        "    pickle.dump(dfsTrainingBalanced, file)\n",
        "with open('dfsValidationBalanced.pkl', 'wb') as file:\n",
        "    pickle.dump(dfsValidationBalanced, file)"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "r-mePis4rxA1"
      },
      "source": [
        "preprocessing"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true,
          "base_uri": "https://localhost:8080/"
        },
        "id": "PN1lDbSsryQj",
        "outputId": "7089db30-6128-4c3f-a817-c7cc46f93253"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/preprocessing/_data.py:173: UserWarning: Numerical issues were encountered when centering the data and might not be solved. Dataset may contain too large values. You may need to prescale your features.\n",
            "  warnings.warn(\"Numerical issues were encountered \"\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/preprocessing/_data.py:173: UserWarning: Numerical issues were encountered when centering the data and might not be solved. Dataset may contain too large values. You may need to prescale your features.\n",
            "  warnings.warn(\"Numerical issues were encountered \"\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/preprocessing/_data.py:173: UserWarning: Numerical issues were encountered when centering the data and might not be solved. Dataset may contain too large values. You may need to prescale your features.\n",
            "  warnings.warn(\"Numerical issues were encountered \"\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/preprocessing/_data.py:173: UserWarning: Numerical issues were encountered when centering the data and might not be solved. Dataset may contain too large values. You may need to prescale your features.\n",
            "  warnings.warn(\"Numerical issues were encountered \"\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/preprocessing/_data.py:173: UserWarning: Numerical issues were encountered when centering the data and might not be solved. Dataset may contain too large values. You may need to prescale your features.\n",
            "  warnings.warn(\"Numerical issues were encountered \"\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/preprocessing/_data.py:173: UserWarning: Numerical issues were encountered when centering the data and might not be solved. Dataset may contain too large values. You may need to prescale your features.\n",
            "  warnings.warn(\"Numerical issues were encountered \"\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/preprocessing/_data.py:173: UserWarning: Numerical issues were encountered when centering the data and might not be solved. Dataset may contain too large values. You may need to prescale your features.\n",
            "  warnings.warn(\"Numerical issues were encountered \"\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/preprocessing/_data.py:173: UserWarning: Numerical issues were encountered when centering the data and might not be solved. Dataset may contain too large values. You may need to prescale your features.\n",
            "  warnings.warn(\"Numerical issues were encountered \"\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/preprocessing/_data.py:173: UserWarning: Numerical issues were encountered when centering the data and might not be solved. Dataset may contain too large values. You may need to prescale your features.\n",
            "  warnings.warn(\"Numerical issues were encountered \"\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/preprocessing/_data.py:173: UserWarning: Numerical issues were encountered when centering the data and might not be solved. Dataset may contain too large values. You may need to prescale your features.\n",
            "  warnings.warn(\"Numerical issues were encountered \"\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/preprocessing/_data.py:173: UserWarning: Numerical issues were encountered when centering the data and might not be solved. Dataset may contain too large values. You may need to prescale your features.\n",
            "  warnings.warn(\"Numerical issues were encountered \"\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/preprocessing/_data.py:173: UserWarning: Numerical issues were encountered when centering the data and might not be solved. Dataset may contain too large values. You may need to prescale your features.\n",
            "  warnings.warn(\"Numerical issues were encountered \"\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/preprocessing/_data.py:173: UserWarning: Numerical issues were encountered when centering the data and might not be solved. Dataset may contain too large values. You may need to prescale your features.\n",
            "  warnings.warn(\"Numerical issues were encountered \"\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/preprocessing/_data.py:173: UserWarning: Numerical issues were encountered when centering the data and might not be solved. Dataset may contain too large values. You may need to prescale your features.\n",
            "  warnings.warn(\"Numerical issues were encountered \"\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/preprocessing/_data.py:173: UserWarning: Numerical issues were encountered when centering the data and might not be solved. Dataset may contain too large values. You may need to prescale your features.\n",
            "  warnings.warn(\"Numerical issues were encountered \"\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/preprocessing/_data.py:173: UserWarning: Numerical issues were encountered when centering the data and might not be solved. Dataset may contain too large values. You may need to prescale your features.\n",
            "  warnings.warn(\"Numerical issues were encountered \"\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/preprocessing/_data.py:173: UserWarning: Numerical issues were encountered when centering the data and might not be solved. Dataset may contain too large values. You may need to prescale your features.\n",
            "  warnings.warn(\"Numerical issues were encountered \"\n"
          ]
        }
      ],
      "source": [
        "dfsTrainingPreprocessed = preprocess(dfsTrainingBalanced)\n",
        "dfsValidationPreprocessed = preprocess(dfsValidationBalanced)"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "JleCIrlUs98K"
      },
      "source": [
        "build sequences"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "GToeQJ4Us_ll"
      },
      "outputs": [],
      "source": [
        "sequencesTraining = buildSequences(dfsTrainingPreprocessed)\n",
        "sequencesValidation = buildSequences(dfsValidationPreprocessed)"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "ab82NbyHtU_L"
      },
      "source": [
        "shuffle"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "uGMjf2k4tV2n"
      },
      "outputs": [],
      "source": [
        "random.shuffle(sequencesTraining)\n",
        "random.shuffle(sequencesValidation)"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "G-ygYD9gtbMx"
      },
      "source": [
        "split sequence from label"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "3Cnkgt0utXt1"
      },
      "outputs": [],
      "source": [
        "train_x, train_y = split(sequencesTraining)\n",
        "validation_x, validation_y = split(sequencesValidation)"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "LXt32q1Tt39k"
      },
      "source": [
        "# Model:"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "QNzTVj7Ue8Vg"
      },
      "source": [
        "hyper parameters bounds"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "mXBNmip7e7or"
      },
      "outputs": [],
      "source": [
        "EPOCHS = 50\n",
        "\n",
        "batchSize = 32\n",
        "layers = 2\n",
        "nodes = 256\n",
        "denseNodes = 128\n",
        "dropOut = 0.8\n",
        "learningRate = 0.0001\n",
        "decay = 1e-06\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XYo0LRjEg2m4"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense, Dropout, LSTM, BatchNormalization\n",
        "from tensorflow.keras.callbacks import ModelCheckpoint\n",
        "import os\n",
        "\n",
        "\n",
        "\n",
        "# model\n",
        "model = Sequential()\n",
        "\n",
        "for _ in range(layers-1):\n",
        "  model.add(LSTM(nodes, activation=\"tanh\", recurrent_activation = 'sigmoid', recurrent_dropout = 0, unroll = False, use_bias = True, input_shape=(train_x.shape[1:]), return_sequences=True))\n",
        "  model.add(Dropout(dropOut))\n",
        "  model.add(BatchNormalization())\n",
        "\n",
        "model.add(LSTM(nodes, activation=\"tanh\", recurrent_activation = 'sigmoid', recurrent_dropout = 0, unroll = False, use_bias = True, input_shape=(train_x.shape[1:])))\n",
        "model.add(Dropout(dropOut))\n",
        "model.add(BatchNormalization())\n",
        "\n",
        "model.add(Dense(denseNodes, activation=\"relu\"))\n",
        "model.add(Dropout(dropOut))\n",
        "\n",
        "model.add(Dense(3, activation=\"softmax\"))\n",
        "\n",
        "\n",
        "\n",
        "# opt  \n",
        "opt = tf.keras.optimizers.Adam(lr=learningRate, decay=decay)\n",
        "\n",
        "\n",
        "model.compile(loss=\"sparse_categorical_crossentropy\",\n",
        "              optimizer = opt,\n",
        "              metrics=[\"accuracy\"])\n",
        "\n",
        "\n",
        "filename = NAME + \"-{epoch:02d}\"\n",
        "filepath = f\"models/{filename}.h5\"\n",
        "checkpoint = ModelCheckpoint(filepath, monitor='val_loss', verbose=0, save_best_only=False, save_weights_only=False, mode='auto', period=1) # saves every epoch\n",
        "\n",
        "\n",
        "# train\n",
        "history = model.fit(\n",
        "  train_x, train_y,\n",
        "  batch_size = batchSize,\n",
        "  epochs = EPOCHS,\n",
        "  validation_data=(validation_x, validation_y),\n",
        "  callbacks=[checkpoint])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "axokGs51bnTA"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [],
      "machine_shape": "hm",
      "name": "modelTrainPreClassified.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.2"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
